{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b22236-611b-49a6-9e17-348a9c67a997",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Landsat Time Series Generation\n",
    "\n",
    "This tutorial demonstrates how to use pee to create Landsat time series images and creating and exporting a LandTrendr fitted time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd3df2-cbef-4bc9-b249-d6e35d29bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee, sys, os, subprocess, rasterio\n",
    "sys.path.append(\"..\") # try to avoid this somehow; maybe by making pee an installed editable package so it's in the path already\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import time_series as ts\n",
    "import landsat as lxtools\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32186e-3df8-4082-b85a-c538cbd33ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a helper function to check on multiple export tasks, which are done throughout the tutorial\n",
    "def check_tasks(task_list):\n",
    "    statuses = [task.status() for task in task_list]\n",
    "    for status in statuses:\n",
    "        if 'start_timestamp_ms' in status.keys():\n",
    "            runtime = (status['update_timestamp_ms'] - status['start_timestamp_ms'])/1000./60\n",
    "        else:\n",
    "            runtime = 0\n",
    "        print(status['description'], status['state'], round(runtime, 2), 'min')\n",
    "    return statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bf571-3269-4e77-8579-52fc5038126a",
   "metadata": {},
   "source": [
    "# Landsat Image Collection\n",
    "Ceate an ee.ImageCollection of Landsat Surface Reflectance images given an area, time frame, and host of other options. This example provides some details on what some parameters are and how to change them, but in general the default settings are pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad50d75-32f8-49d7-ba96-1ff228c3d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use a Geometry, Feature, or featureCollection for spatial filtering of the images\n",
    "# This is just past to filterBounds\n",
    "aoi = ee.FeatureCollection('TIGER/2018/Counties').filterMetadata('NAME', 'equals', 'Larimer')\n",
    "\n",
    "# Start and end can be anything accepted by filterDate\n",
    "# NOTE: end is exclusive but start, startdoy and enddoy are inclusive\n",
    "start = '2018'\n",
    "end = '2019'     # since end is exclusive, using '2019' as end will filter to only 2018 images\n",
    "\n",
    "# If filtering a collection of multiple years using 'start' and 'end' you can use\n",
    "# start day of year and end day of year parameters\n",
    "# to filter to a time frame within each year.\n",
    "startdoy = 152   # June 1st\n",
    "enddoy = 273     # Sept 30th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733af1c-c90b-4b8f-a60b-deb31f3a73de",
   "metadata": {},
   "source": [
    "**Cloud masking**  \n",
    "Cloud masking here is a catch-all phrase for masking out clouds, snow, water, saturated pixels, etc, etc. The surface reflectance images come with several quality assurance bands to apply cloud masking through bit masks. The sr_mask function simplifies the various masking options. \n",
    "\n",
    "sr_mask calls pqa_mask which by default filters the pqa band for \"clear\" pixels with no water, shadows, clouds, or snow and which have not been filled. It also filters for pixels for pixels that have \"confidence\" values for a \"low\" chance of normal or cirrus clouds. You can change these options by specifying water=1 if you want only pixels that have water or water=None if you want to keep both water or non-water pixels. For confidence values you can give cloud_conf=2 if you want to accept pixels that have a 'medium' chance of being clouds.\n",
    "\n",
    "sr_mask also filters for pixels in the valid data range of 0 to 10,000 for optical bands and which don't have radiometric saturation according the rad_qa band. Note that blue and coastal blue are often oversaturation, so this may filter more pixels than desired. In Landsat 5 some edge pixels don't have values for all bands, and these pixels are masked out by default as well. For Landsat 8, aerosols can be masked out too.\n",
    "\n",
    "Below we bundle these options into a dictionary that is passed to the sr_mask function. See the sr_mask function, pqa_mask function and Landsat product guides for details on applying cloud masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51a95d-60a2-4b93-90a9-4e5fa6fc1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets allow water and only use the confidence bands for cloud masking since the product guides\n",
    "# recommend using either the cloud and clear switches or the confidence bands, not both.\n",
    "mask_kwargs = {'water':None,\n",
    "               'clear':None,\n",
    "               'cloud':None,\n",
    "               'cloud_conf':2,  # allow low and medium confidence clouds\n",
    "               'cirrus_conf':1  # only low confidence cirrus filtering (only for L8)\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36d5cb-4d92-4453-a973-232190c7bed1",
   "metadata": {},
   "source": [
    "**Temporal Dark Outlier Mask**  \n",
    "The F-mask algorithm is fairly effective at identifying clouds, snow and water, but often misses cloud shadows. Cloud shadows that are not masked out correctly can have problems particularly for mapping forest structure since shadows have a strong effect on the SWIR bands. To more be more rigorous in removing cloud shadows we can tack on the Temporary Dark Outlier Mask (TDOM) algorithm. This method uses a long time series of the pixel to identify outliers that are dark in SWIR and NIR. By default a morphological opening is also applied to this mask. To use TDOM the pixel level mean and standard deviation needs to be calculated across a fairly long time series, so it's best if precomputed stats images are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ecf8f1-efc2-4440-9fa1-c6f2732c5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load statistics images that were precalculated by GTAC for use with TDOM\n",
    "# These images have bands of the mean and standard deviation for different landsat bins using\n",
    "# data up to 2019 which is enough to calculate if the pixels in each image are outliers.\n",
    "TDOMStats = ee.ImageCollection('projects/lcms-tcc-shared/assets/CS-TDOM-Stats/TDOM').mosaic()#.divide(10000) divide if using 0-1 imagery, don't if using unscaled images (0-10,000)\n",
    "\n",
    "# select and rename the bands to use for TDOM so that the band names match the names of image collection we'll be making\n",
    "mean_img = TDOMStats.select(['Landsat_nir_mean', 'Landsat_swir1_mean'], ['nir', 'swir1']) \n",
    "stddev_img = TDOMStats.select(['Landsat_nir_stdDev', 'Landsat_swir1_stdDev'], ['nir', 'swir1'])\n",
    "\n",
    "# Make a dictionary of arguments to pass to TDOM including the mean and stddev images to use\n",
    "# Since we're using the unscaled TDOMStats images we'll using a sum threshold of 3500 instead of the default 0.35\n",
    "tdom_kwargs = {'mean_img':mean_img, 'stddev_img':stddev_img, 'sum_thresh':3500}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20474d2-9650-424e-a7ba-70ed3296583e",
   "metadata": {},
   "source": [
    "All of the parameters for setting up an image collection are fed into a single function that filters images from the given Landsat satellite collections, renames the bands, applies cloud masking, and harmonizes Landsat 8 to match Landsat 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277322a-aa02-4d0c-8921-361298e6195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = lxtools.sr_collection(\n",
    "            aoi, start, end,        # Area, start date, and end date are required parameters\n",
    "            startdoy,\n",
    "            enddoy,\n",
    "            sats=[\"LANDSAT_7\", \"LANDSAT_8\"],\n",
    "#             harmonize=True,        # This harmonizes L8 to match L5/7 since they have slightly different band widths, but people debate whether this is really needed\n",
    "            rescale=False,         # Since we're using the unscaled (0-10k) TDOM stats we'll also not scale the images here\n",
    "            cloud_cover=50,        # Filter out images that have greater than 50% cloud cover. Images with lots of cloud cover often have some unmasked clouds and cloud shadows\n",
    "            slc_on=False,          # If true then only using L7 images when the scan line corrector was working (January 1998 - May 2003)\n",
    "            tdom=True,\n",
    "            exclude=['LE07_033032_20180612', 'LC08_034031_20180729'],          # You can provide a list of specific images to exclude by their system:index\n",
    "            mask_kwargs=mask_kwargs,\n",
    "            tdom_kwargs=tdom_kwargs\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e5e7b-b788-4a2d-ae59-50a8d97cf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of images in the filtered collection\n",
    "images.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb3bd1-0d09-4508-a25d-0ce982a2bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first image is from June 2nd and the last is from Sept 30th\n",
    "print(ee.Date(images.aggregate_min('system:time_start')).format('YYYY-MM-dd').getInfo())\n",
    "print(ee.Date(images.aggregate_max('system:time_start')).format('YYYY-MM-dd').getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d46e20-691c-4f66-8474-51231e90fe18",
   "metadata": {},
   "source": [
    "## Compositing and Spectral Indices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c92ebf-9461-46d0-83e5-e35a79b60d53",
   "metadata": {},
   "source": [
    "### One year composite\n",
    "Lets composite this one year summer image collection into a single image that should be representative of the conditions over summer. We'll do this using the medoid operation which is like a multidimensional median. First we'll filter to the shared set of optical bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1c9bd-b9b0-4c37-af4a-54cb99d1f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of L7 optical bands\n",
    "l7_opt = lxtools.__sr_dict['LANDSAT_7']['opt']\n",
    "l7_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0be7dc-08ae-4f53-ae29-5bcd47b02bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.select(l7_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b244a-be6a-474d-83a2-6ae10e4a115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the medoid using just a few bands, and add a band with day of year for the pixel selected from the collection\n",
    "img = ts.medoid(images, med_bands = ['red', 'nir', 'swir1'], date_band=True)\n",
    "img.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3f609-bc24-483e-bfea-15d9b56f8107",
   "metadata": {},
   "source": [
    "You can see that all bands were retained but only red, nir and swir1 were used in the medoid calculation. A 'date' band with the day of year was also added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd49075-4b73-4751-a628-8724ce2b68a2",
   "metadata": {},
   "source": [
    "Let's calculate some spectral indices from this medoid composite. Since the medoid selects a single pixel from a specific date the band interrelationships are maintained so calculating spectral indices from the composite is still valid. This would not be the case if we used a different compositing method like the median or mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef179d-6063-435f-86bc-9a0566a900b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the NDVI, NDMI, and all tasseled cap indices\n",
    "specs = lxtools.specixs(img, ixlist=['ndvi', 'ndmi', 'tcw', 'tcb'])#'tasseled_cap'])\n",
    "specs.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070130c-9030-42d1-8d05-b87de27e44b6",
   "metadata": {},
   "source": [
    "### Annual Composites\n",
    "If you need image composites over multiple years this process can be simplified with the annual composites function, which takes all of the same parameters and a compositing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3f562-03fe-4357-ae1d-1cb7bac8b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use several years a wider \n",
    "starty = 2015\n",
    "endy = 2020   # end inclusive\n",
    "\n",
    "# Bundle all the collection arguments from before into a single dictionary\n",
    "# Note that it's only necessary to provide keyword arguments where the options we want are different from the defaults\n",
    "coll_kwargs = {\n",
    "    'rescale':False,\n",
    "    'bands':['blue', 'green', 'red', 'nir', 'swir1', 'swir2'],\n",
    "    'cloud_cover':50,\n",
    "    'tdom':True,\n",
    "    'mask_kwargs':mask_kwargs,\n",
    "    'tdom_kwargs':tdom_kwargs,\n",
    "    'exclude': ['LE07_033032_20180612', 'LC08_034031_20180729']  # In this case let's exclude a couple images we don't want using their system:index in their original collections\n",
    "}\n",
    "\n",
    "comps = ts.annual_composites(\n",
    "            aoi, starty, endy, startdoy, enddoy,       # use the same spatial and day of year filters as before\n",
    "            coll_func = lxtools.sr_collection,         # You can provide a different function for obtaining the collection if you want\n",
    "            comp_func = ee.ImageCollection.median,     # This time lets just use the median function in GEE\n",
    "            coll_kwargs=coll_kwargs,\n",
    "            fill=True                                  # Fill years with no images after filtering with an empty image, this is needed for LandTrendr \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fa8c1-dc89-4b63-be32-07f234fb79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 6 images. \n",
    "print(comps.size().getInfo())\n",
    "\n",
    "# One for each year from 2015 to 2020\n",
    "print(comps.aggregate_array('year').getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc410b-07db-45f1-bd9c-6bbca19511bc",
   "metadata": {},
   "source": [
    "**Annual composites with spectral indices**  \n",
    "We can calculate spectral indices for each composite, but since we used the median which could be from different dates for each band, it's better to calculate spectral indices before compositing. Perhaps the easiest way to do this is by adding the spectral index calculation as the first step in the compositing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610f238-94d2-4111-b2bb-425d7e07baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_specix(imgs, ixlist=None):\n",
    "    \"\"\" For the set of images in each year calculate spectral indices and return the annual median.\n",
    "    \"\"\"\n",
    "    imgs = imgs.map(lambda i: lxtools.specixs(i, ixlist=ixlist))\n",
    "    img = imgs.median()\n",
    "    return img\n",
    "\n",
    "comps = ts.annual_composites(\n",
    "            aoi, starty, endy, startdoy, enddoy,\n",
    "            coll_func = lxtools.sr_collection,\n",
    "            comp_func = median_specix,\n",
    "            coll_kwargs=coll_kwargs,\n",
    "            comp_kwargs = {'ixlist':['ndvi', 'nbr']},   # we'll get these spectral indices before compositing\n",
    "            fill=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c1d7f-7ec3-4743-93a9-205dd26cb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We still have an image for every year\n",
    "print(comps.aggregate_array('year').getInfo())\n",
    "\n",
    "# Now they're the median ndvi and nbr values\n",
    "print(comps.first().bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f013c-4c91-4cee-b079-c9e7046cdfbd",
   "metadata": {},
   "source": [
    "## Exporting Tiles\n",
    "We generally work over large areas so when working with images locally, tiling is the often the most efficient way to store a set of images covering an area. We'll export the annual composites we just made in a set of Landsat Analysis Ready Data (ARD) tiles covering Larimer county. \n",
    "\n",
    "Here I use a previously stored copy of the Landsat ARD tiles that I've uploaded as a GEE asset, but you could use any GEE feature collection with polygons specifying different aois that you want to make exact exports for. The tile features have attributes that give the min and max coordinates of the tile in the CONUS Albers project (EPSG:5070), which is what's used for ARD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9dd860-80a7-4c63-a10a-942c5f4b2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for ARD tiles intersecting the AOI\n",
    "aoi = ee.FeatureCollection('TIGER/2018/Counties').filterMetadata('NAME', 'equals', 'Larimer')\n",
    "tilesfc = ee.FeatureCollection(\"users/stevenf/other/conus_ard_grid_coords\")\n",
    "tilesfc = tilesfc.filterBounds(aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8f30b-8fb5-4d9a-bd1a-6e94d65c4ac4",
   "metadata": {},
   "source": [
    "Creating a separate composite set for each tile may reduce some unnecessary processing for GEE on the back end and speed up the export. So we'll create the composites within the tile exporting loop rather than just creating the composite set for the entire aoi. In general it's best to first do as much filtering of images as you can for a specific output, in this case filtering images to just the tile rather than the entire AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3cdeb7-f41e-49b1-855e-0976930ec89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of tiles to loop over\n",
    "tilehvs = tilesfc.aggregate_array('hv').getInfo()\n",
    "tilehvs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b998fc7-2874-4b0a-a2a2-3591b2381ebd",
   "metadata": {},
   "source": [
    "For ARD tiles the 'hv' attribute gives the horizonal cell number plus the vertical cell number. For example, '011008' is horizontal cell 011 and vertical cell 008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9ca7b-d0f4-4ec7-be8f-6062bb541601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify annual composite collection parameters\n",
    "\n",
    "# time filtering\n",
    "starty = 2018\n",
    "endy = 2019 \n",
    "startdoy = 152   # June 1st\n",
    "enddoy = 273     # Sept 30th\n",
    "\n",
    "# TDOM set up\n",
    "TDOMStats = ee.ImageCollection('projects/lcms-tcc-shared/assets/CS-TDOM-Stats/TDOM').mosaic()\n",
    "mean_img = TDOMStats.select(['Landsat_nir_mean', 'Landsat_swir1_mean'], ['nir', 'swir1']) \n",
    "stddev_img = TDOMStats.select(['Landsat_nir_stdDev', 'Landsat_swir1_stdDev'], ['nir', 'swir1'])\n",
    "tdom_kwargs = {'mean_img':mean_img, 'stddev_img':stddev_img, 'sum_thresh':3500}\n",
    "\n",
    "# Masking differences from defaults\n",
    "mask_kwargs = {\n",
    "    'water':None\n",
    "}\n",
    "\n",
    "# Collection options\n",
    "coll_kwargs = {\n",
    "    'rescale':False,\n",
    "    'bands':['red', 'nir', 'swir1', 'swir2'],  # these are the only ones needed for TDOM and creating NDVI and NBR\n",
    "    'cloud_cover':50,\n",
    "    'tdom':True,\n",
    "    'mask_kwargs':mask_kwargs,\n",
    "    'tdom_kwargs':tdom_kwargs,\n",
    "    'exclude': ['LE07_033032_20180612', 'LC08_034031_20180729']\n",
    "}\n",
    "\n",
    "# Compositing function\n",
    "def median_specix(imgs):\n",
    "    imgs = imgs.map(lambda i: lxtools.specixs(i, ixlist=['ndvi', 'nbr']))\n",
    "    return imgs.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c916cc-b2ef-4078-8176-edac81101a31",
   "metadata": {},
   "source": [
    "### Separate - one image per tile and year\n",
    "This method is straighforward but slower to export overall (~7 min per tile, 22 min overall). The advantage is that image bands don't need to be rearranged after export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16485b78-3b22-4141-a425-1dc65254135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export one annual composite image for each tile and year\n",
    "task_list = []\n",
    "years = np.arange(starty, endy+1)\n",
    "for hv in tilehvs:\n",
    "    for year in years:\n",
    "        print(hv, year)\n",
    "        tile = ee.Feature(tilesfc.filterMetadata('hv', 'equals', hv).first())\n",
    "        tprops = tile.toDictionary().getInfo()\n",
    "\n",
    "        # Create the composite for one year\n",
    "        imgs = lxtools.sr_collection(\n",
    "            tile.geometry(),\n",
    "            str(year), str(year+1), startdoy, enddoy,\n",
    "            **coll_kwargs\n",
    "        )\n",
    "        imgs = imgs.map(lambda i: lxtools.specixs(i, ixlist=['ndvi', 'nbr']))\n",
    "        img = imgs.median()\n",
    "        \n",
    "        # Cast to Int16 for a smaller export\n",
    "        img = img.multiply(1000).toInt16()\n",
    "\n",
    "        # Set the nodata values, otherwise they'll be 0, which is a valid value\n",
    "        img = img.unmask(-32768)\n",
    "\n",
    "        # Setup for exporting the exact tile extent and resolution.\n",
    "        outname = 'ls_'+hv+'_'+str(year)\n",
    "        crs='epsg:5070'\n",
    "        scale = 30.0\n",
    "        dimx = int((tprops['maxx'] - tprops['minx'])/scale)\n",
    "        dimy = int((tprops['maxy'] - tprops['miny'])/scale)\n",
    "        dims = str(dimx)+'x'+str(dimy)\n",
    "        transform = [scale, 0.0, float(tprops['minx']), 0.0, -scale, float(tprops['maxy'])]\n",
    "\n",
    "        # Make sure a single file is used\n",
    "        shardSize = 256\n",
    "        fileDimensions = (int(np.ceil(dimx / shardSize) * shardSize), int(np.ceil(dimy / shardSize) * shardSize))\n",
    "        nbands = (endy-starty+1) * len(coll_kwargs['bands'])\n",
    "\n",
    "        # to drive\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=img, \n",
    "            description=outname,\n",
    "            fileNamePrefix=outname,\n",
    "            folder = \"gee\",\n",
    "            dimensions=dims,\n",
    "            crs=crs,\n",
    "            crsTransform=str(transform),\n",
    "            maxPixels=float(dimx)*dimy*nbands,\n",
    "            fileDimensions=fileDimensions\n",
    "        )\n",
    "\n",
    "        task_list.append(task)\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da406f6-09ac-4c96-a3de-6c3e323fbbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = check_tasks(task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6b71c-572e-4c0c-a371-45dae6a3db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minutes to complete\n",
    "(statuses[-1]['update_timestamp_ms'] - statuses[0]['creation_timestamp_ms']) / 1000 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f47d8c-cca7-4943-a2a9-7817212f4101",
   "metadata": {},
   "source": [
    "### Stacked - one tile, all years\n",
    "This method is faster to export (~7 min per tile, ~9 min overall with multiple tasks running). However, the images from annual export need to be stacked into a single image and then unstacked after export, which also takes some time. \n",
    "\n",
    "In general for annual composites, it seems that exporting all bands and years in a single image tends to be much faster. The more bands and years you're exporting the better this method is in comparison to single year exports. However, GEE has a limit of 16 GB uncompressed for a single image export task, which is 320 bands in 16-bit image for a 5k x 5k ARD tile. Note that runtimes depend on the google server load, so they can vary quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69016d-100e-429d-b153-1434f5016f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the tiles to create the composite collection and export one image for each tile\n",
    "# with years and bands stacked for faster export (takes ~7 minutes per tile)\n",
    "task_list = []\n",
    "for hv in tilehvs:\n",
    "    print(hv)\n",
    "    tile = ee.Feature(tilesfc.filterMetadata('hv', 'equals', hv).first())\n",
    "    tprops = tile.toDictionary().getInfo()\n",
    "    \n",
    "    # Create the annual composite collection\n",
    "    comps = ts.annual_composites(\n",
    "        tile.geometry(),\n",
    "        starty, endy, startdoy, enddoy,\n",
    "        lxtools.sr_collection, \n",
    "        median_specix,\n",
    "        coll_kwargs,\n",
    "        fill=True\n",
    "    )\n",
    "    \n",
    "    # Stack the images into bands of year_band for faster export\n",
    "    comps = comps.sort('sytem:time_start')\n",
    "    img = ts.stack_annual(comps) # stack annual depends on the images having a 'year'bb property\n",
    "    \n",
    "    # Cast to Int16 for a smaller export\n",
    "    img = img.multiply(1000).toInt16()\n",
    "    \n",
    "    # Set the nodata values, otherwise they'll be 0, which is a valid value\n",
    "    img = img.unmask(-32768)\n",
    "    \n",
    "    # Setup for exporting the exact tile extent and resolution.\n",
    "    outname = 'ls_'+hv\n",
    "    crs='epsg:5070'\n",
    "    scale = 30.0\n",
    "    dimx = int((tprops['maxx'] - tprops['minx'])/scale)\n",
    "    dimy = int((tprops['maxy'] - tprops['miny'])/scale)\n",
    "    dims = str(dimx)+'x'+str(dimy)\n",
    "    transform = [scale, 0.0, float(tprops['minx']), 0.0, -scale, float(tprops['maxy'])]\n",
    "    \n",
    "    # Make sure a single file is used\n",
    "    shardSize = 256\n",
    "    fileDimensions = (int(np.ceil(dimx / shardSize) * shardSize), int(np.ceil(dimy / shardSize) * shardSize))\n",
    "    nbands = (endy-starty+1) * len(coll_kwargs['bands'])\n",
    "\n",
    "    # to drive\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=img, \n",
    "        description=outname,\n",
    "        fileNamePrefix=outname,\n",
    "        folder = \"gee\",\n",
    "        dimensions=dims,\n",
    "        crs=crs,\n",
    "        crsTransform=str(transform),\n",
    "        maxPixels=float(dimx)*dimy*nbands,\n",
    "        fileDimensions=fileDimensions\n",
    "    )\n",
    "    \n",
    "    task_list.append(task)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8c915-834b-42c9-a0e9-0285a2784fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = check_tasks(task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea6bba-5f0b-407f-bf09-089ca61121bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minutes from start to end\n",
    "(statuses[-1]['update_timestamp_ms'] - statuses[0]['creation_timestamp_ms']) / 1000 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed4065-eb60-4700-97b3-6c75df557c43",
   "metadata": {},
   "source": [
    "### Sorting Stacked Images\n",
    "If you export an image stacked with bands labeled as \"year_bandname\", you may want to reorganize them after export. I will typically organize images into a \"tile\" folder with subfolders for each year and all the spectral bands stored in each image. This makes it easy to create virtual mosaics of all the tiles in a single year subfolder and then visualize multiple spectral bands in GIS software.\n",
    "\n",
    "Since GEE exports images as pixel-interleaved not band-interleaved, reading in images with many bands can be very slow, but it's still typically much faster than exporting many separate images from GEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8e5a3-c5b0-42e0-8d65-fb02c776aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the input and output folder and parameters\n",
    "# Make sure that your annual composite tiles are the only images in your GEE folder or move them to a separate folder\n",
    "indir = r\"E:\\My Drive\\gee\"\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "\n",
    "outdir = r\"C:\\scratch\"\n",
    "temp=\"{base}_{tile}.tif\"\n",
    "multi = None\n",
    "nodata = -32768\n",
    "basename='ls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb62b36-5ef3-4134-8efd-e99be7ff87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sorting\n",
    "ts.split_stack(paths, outdir, basename, temp=temp, nodata=nodata, multi=multi, threads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d9409-e79d-4919-946f-3a76abc45aad",
   "metadata": {},
   "source": [
    "# LandTrendr Time Series\n",
    "An image collection like above can also be run through the LandTrendr temporal segmentation algorithm prior to export to provide 'fitted' estimates of spectral reflectance that reduce year to year variations that are likely not do to on the ground changes.\n",
    "\n",
    "The 'lt_fitted' function runs an annual image collection through Landtrendr and fits each band independently by default, but a single band can also be used for determining the vertices with remaining bands fit to that temporal segmentation. Additional keyword arguments for LandTrendr parameters are passed on to ee.Algorithms.TemporalSegmentation.LandTrendr.\n",
    "\n",
    "The below example shows how to export a set of tiles run through LandTrendr with two files having different spectral bands or indices exported for each tile. Each band and spectral index is temporally segmented independently. \n",
    "\n",
    "Splitting the tile export into multiple files with different bands may be necessary to stay under the 16GB uncompressed export limit. This is true whether you're exporting a regular annual composite time series or LandTrendr time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34128d9e-0379-4b8d-8605-ac2ce63d8d0c",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59828f0-79f5-4c17-a8ca-6b71880992d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for ARD tiles intersecting the AOI\n",
    "aoi = ee.FeatureCollection('TIGER/2018/Counties').filterMetadata('NAME', 'equals', 'Larimer')\n",
    "tilesfc = ee.FeatureCollection(\"users/stevenf/other/conus_ard_grid_coords\")\n",
    "tilesfc = tilesfc.filterBounds(aoi)\n",
    "\n",
    "# Get a list of tiles to loop over\n",
    "tilehvs = tilesfc.aggregate_array('hv').getInfo()\n",
    "tilehvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27576d97-c4cb-48b3-b835-c608d1cea7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify annual composite collection parameters\n",
    "\n",
    "# time filtering\n",
    "# In this example we only use 10 years, but you'd typically want to run LandTrendr on the full Landsat time series (1984-present)\n",
    "starty = 2010\n",
    "endy = 2019 \n",
    "startdoy = 152   # June 1st\n",
    "enddoy = 273     # Sept 30th\n",
    "\n",
    "# TDOM set up\n",
    "TDOMStats = ee.ImageCollection('projects/lcms-tcc-shared/assets/CS-TDOM-Stats/TDOM').mosaic()\n",
    "mean_img = TDOMStats.select(['Landsat_nir_mean', 'Landsat_swir1_mean'], ['nir', 'swir1']) \n",
    "stddev_img = TDOMStats.select(['Landsat_nir_stdDev', 'Landsat_swir1_stdDev'], ['nir', 'swir1'])\n",
    "tdom_kwargs = {'mean_img':mean_img, 'stddev_img':stddev_img, 'sum_thresh':3500}\n",
    "\n",
    "# Masking differences from defaults\n",
    "mask_kwargs = {\n",
    "    'water':None\n",
    "}\n",
    "\n",
    "# Export different sets of bands in multiple files\n",
    "bdict = {'orig':['red', 'nir', 'swir1', 'swir2'],\n",
    "         'spix':['ndvi', 'nbr', 'ndmi']}\n",
    "\n",
    "# Collection options\n",
    "coll_kwargs = {\n",
    "    'rescale':False,\n",
    "    'bands':bdict['orig'], # At least nir and swir1 are needed for TDOM\n",
    "    'cloud_cover':50,\n",
    "    'tdom':True,\n",
    "    'mask_kwargs':mask_kwargs,\n",
    "    'tdom_kwargs':tdom_kwargs,\n",
    "    'exclude': ['LE07_033032_20180612', 'LC08_034031_20180729']\n",
    "}\n",
    "\n",
    "# LandTrendr parameters\n",
    "lt_kwargs = { \n",
    "  'maxSegments':            6,\n",
    "  'spikeThreshold':         0.9,\n",
    "  'vertexCountOvershoot':   3,\n",
    "  'preventOneYearRecovery': True,\n",
    "  'recoveryThreshold':      0.25,\n",
    "  'pvalThreshold':          0.05,\n",
    "  'bestModelProportion':    0.75, # LCMS uses 1.25\n",
    "  'minObservationsNeeded':  6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f976c4-3099-4e38-9fc6-d0e37aa703a1",
   "metadata": {},
   "source": [
    "## Export\n",
    "Run the export process just like with the annual mosaics, but use the medoid composite and calculate spectral indices from the medoid image.  \n",
    "This should take about 25 minutes to complete per image and 50 minutes total depending on server load and how many tasks run concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b12b80-b990-4a21-9615-9c59953b2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export LT fitted time series for each tile with original bands and spectral indices in separate files\n",
    "task_list = []\n",
    "for hv in tilehvs:\n",
    "    tile = ee.Feature(tilesfc.filterMetadata('hv', 'equals', hv).first())\n",
    "    tprops = tile.toDictionary().getInfo()\n",
    "    \n",
    "    # Create the annual composite collection\n",
    "    comps = ts.annual_composites(\n",
    "        tile.geometry(),\n",
    "        starty, endy, startdoy, enddoy,\n",
    "        lxtools.sr_collection, \n",
    "        ts.medoid,\n",
    "        coll_kwargs,\n",
    "        fill=True       # Filling years with no images with an empty composite image is necessary for LandTrendr\n",
    "    )  \n",
    "    \n",
    "    for k, bands in bdict.items():\n",
    "        print(hv, k)\n",
    "        if k=='spix':\n",
    "            # Get spectral indices and convert to int16 range\n",
    "            # Note that calculating spectral indices on the composite is fine since medoid was used.\n",
    "            # If using median, spectral indices should be calculated for each image prior to compositing.\n",
    "            comps = comps.map(lambda i: (lxtools.specixs(i, ixlist=bands)\n",
    "                                                .multiply(1000)\n",
    "                                                .copyProperties(i, i.propertyNames())))\n",
    "        \n",
    "        # Run LT and extract fit\n",
    "        imgs_fit = ts.lt_fitted(comps, flip_bands=True, fit_band=None, **lt_kwargs)\n",
    "    \n",
    "        # Stack the images into bands of year_band for faster export\n",
    "        imgs_fit = imgs_fit.sort('sytem:time_start')\n",
    "        img = ts.stack_annual(imgs_fit) # stack annual depends on the images having a 'year'bb property\n",
    "    \n",
    "        # Cast to Int16 for a smaller export\n",
    "        img = img.toInt16()\n",
    "\n",
    "        # Set the nodata values, otherwise they'll be 0, which is a valid value\n",
    "        img = img.unmask(-32768)\n",
    "\n",
    "        # Setup for exporting the exact tile extent and resolution.\n",
    "        outname = 'lt_'+hv+'_'+k\n",
    "        crs='epsg:5070'\n",
    "        scale = 30.0\n",
    "        dimx = int((tprops['maxx'] - tprops['minx'])/scale)\n",
    "        dimy = int((tprops['maxy'] - tprops['miny'])/scale)\n",
    "        dims = str(dimx)+'x'+str(dimy)\n",
    "        transform = [scale, 0.0, float(tprops['minx']), 0.0, -scale, float(tprops['maxy'])]\n",
    "\n",
    "        # Make sure a single file is used\n",
    "        shardSize = 256\n",
    "        fileDimensions = (int(np.ceil(dimx / shardSize) * shardSize), int(np.ceil(dimy / shardSize) * shardSize))\n",
    "        nbands = (endy-starty+1) * len(coll_kwargs['bands'])\n",
    "\n",
    "        # to drive\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=img, \n",
    "            description=outname,\n",
    "            fileNamePrefix=outname,\n",
    "            folder = \"gee\",\n",
    "            dimensions=dims,\n",
    "            crs=crs,\n",
    "            crsTransform=str(transform),\n",
    "            maxPixels=float(dimx)*dimy*nbands,\n",
    "            fileDimensions=fileDimensions\n",
    "        )\n",
    "\n",
    "        task_list.append(task)\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f0ae3-e352-45e3-8251-d5d2cd49edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = check_tasks(task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44574ae-4276-437c-8326-884f508990bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minutes from start to end\n",
    "(statuses[-1]['update_timestamp_ms'] - statuses[0]['creation_timestamp_ms']) / 1000 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e06b9-db0d-4bac-a695-75bb7414cd98",
   "metadata": {},
   "source": [
    "## Sort LT Stacked Images\n",
    "This is the same as sorting the annual composites above, but now we have bands split into multiple files for each tile ('orig' and 'spix'). So the parameters and template need to be set up to organize these bands together into a single file per year.\n",
    "\n",
    "Make sure the LT fitted images just exported are the only files in 'indir' before sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7ea84-373b-48bc-8bae-95c8d70310d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the input and output folder and parameters\n",
    "# Make sure that your annual composite tiles are the only images in your GEE folder or move them to a separate folder\n",
    "indir = r\"E:\\My Drive\\gee\"\n",
    "paths = glob(os.path.join(indir, \"*.tif\"))\n",
    "\n",
    "outdir = r\"G:\\tiles\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "temp=\"{base}_{tile}_{multi}.tif\"\n",
    "multi = ['orig', 'spix']\n",
    "nodata = -32768\n",
    "basename='lt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810e147-75e8-4071-aa29-4d23dafb165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sorting\n",
    "ts.split_stack(paths, outdir, basename, temp=temp, nodata=nodata, multi=multi, threads=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638797a-eff7-4295-a0b1-63ac65e15c36",
   "metadata": {},
   "source": [
    "# Mosaic Tiles\n",
    "Either annual composites or Landtrendr annual time series exported as tiles can be mosaiced together into a single virtual image (VRT). Making a virtual image is fast and avoids duplicating the data. VRTs are just XML files that describe what files GIS software should look for when pulling up an image in a certain area.  You can use input paths relative (like below) to the output VRT to be able to move both the tiles and the virtual mosaics together and have the mosaics still work.  \n",
    "This snippet uses gdalbuildvrt which requires gdal to be installed in your current python environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e23fbf-10bd-48fe-ac2f-973eb12ba657",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_dir = r\"G:\\mosaics\"\n",
    "tile_dir = r\"G:\\tiles\"\n",
    "\n",
    "years = os.listdir(tile_dir)\n",
    "os.makedirs(mosaic_dir, exist_ok=True)\n",
    "\n",
    "# don't specify an absolute for the VRT if needing relative paths to the tiffs\n",
    "cwd = os.getcwd()\n",
    "os.chdir(mosaic_dir)\n",
    "\n",
    "for y in years:\n",
    "    # create vrt\n",
    "    outname = \"lt_larimer_\"+y+\".vrt\"\n",
    "    paths = glob(os.path.join(tile_dir, y, \"*.tif\"))\n",
    "    paths = [os.path.relpath(p, mosaic_dir) for p in paths]\n",
    "    paths.sort()\n",
    "    cmd = \"gdalbuildvrt \" + outname + \" \" + \" \".join(paths)\n",
    "    stdout = subprocess.check_output(cmd)\n",
    "\n",
    "    # set band descriptions\n",
    "    with rasterio.open(paths[0]) as src:\n",
    "        descs = src.descriptions\n",
    "    with rasterio.open(outname, 'r+') as src:\n",
    "        src.descriptions = descs\n",
    "        \n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa48fa-e083-4a78-9ed9-c4e7f3fd13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(mosaic_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02474542-8b2f-4006-972d-af7ac43d8464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ecofor]",
   "language": "python",
   "name": "conda-env-ecofor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
